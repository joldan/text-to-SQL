{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8eeb7172-6a4d-46d9-8e62-eeccf1e63591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms  import LlamaCpp\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.utilities import SQLDatabase\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import openai\n",
    "import time\n",
    "import ast\n",
    "import sqlite3\n",
    "\n",
    "# Callbacks support token-wise streaming\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a69740a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = 'ADD_YOUR_API_KEY_HERE'\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "model_prices = [{'model':'gpt-4-1106-preview','input_price':10,'output_price':30},\n",
    "                {'model':'gpt-3.5-turbo-0125','input_price':0.5,'output_price':1.5},\n",
    "                {'model':'davinci-002','input_price':2,'output_price':2},\n",
    "                {'model':'babbage-002','input_price':0.4,'output_price':0.4}]\n",
    "\n",
    "client = openai.OpenAI()\n",
    "\n",
    "#change model name to use different model\n",
    "model_name = \"gpt-3.5-turbo-0125\"\n",
    "\n",
    "#For davinci of babage use this generation function\n",
    "def base_model_generation(prompt):\n",
    "  response = openai.completions.create(\n",
    "    model = model_name ,\n",
    "    prompt=prompt,\n",
    "    n = 1,\n",
    "    stream = False,\n",
    "    temperature=0.0,\n",
    "    max_tokens=600,\n",
    "    top_p = 1.0,\n",
    "      \n",
    "    frequency_penalty=0.0,\n",
    "    presence_penalty=0.0,\n",
    "    stop = [\"SQL\"]\n",
    "  ) \n",
    "  return response.choices[0].text, response.usage.prompt_tokens, response.usage.completion_tokens\n",
    "\n",
    "#For GPT3.5 and GPT4 use this generation function\n",
    "def GPT_generation(system_prompt, user_prompt):\n",
    "  response = client.chat.completions.create(\n",
    "    model= model_name ,\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt},{\"role\": \"user\", \"content\": user_prompt}],\n",
    "    n = 1,\n",
    "    stream = False,\n",
    "    temperature=0.0,\n",
    "    max_tokens=600,\n",
    "    top_p = 1.0,\n",
    "    \n",
    "    frequency_penalty=0.0,\n",
    "    presence_penalty=0.0,\n",
    "  )\n",
    "  return response.choices[0].message.content, response.usage.prompt_tokens, response.usage.completion_tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b262ad0-6347-4379-ac01-6c3955adc2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPIDER_DB_DIR = '/Users/joaquinoldan/Documents/MASTER_AI/4-Tesis/spider/database/' #the path were all databases exist\n",
    "DATASET_SCHEMA = '/Users/joaquinoldan/Documents/MASTER_AI/4-Tesis/spider/tables.json'\n",
    "DATASET = '/Users/joaquinoldan/Documents/MASTER_AI/4-Tesis/spider/dev.json'\n",
    "\n",
    "OUTPUT_FILE = '/Users/joaquinoldan/Documents/MASTER_AI/4-Tesis/A -Github/SQL_GPU/results/gpt'\n",
    "INPUT_FILE = '/Users/joaquinoldan/Documents/MASTER_AI/4-Tesis/A-Github/lalossSQL/SQL_GPU/results/gpt/tables-GTP3.5-turbo-0-300.json'\n",
    "\n",
    "def load_data_json(DATASET):\n",
    "    # Open the JSON file and load data\n",
    "    with open(DATASET, 'r') as json_file:\n",
    "        return json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17e31f3f-cb95-46a8-a47b-e68693cc4786",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Modificar esto eventualmente por una tecnica de RAG\n",
    "def getSQLDatabase(db_id):\n",
    "    # Modificar el PATH para donde este la base de datos\n",
    "    db_path = SPIDER_DB_DIR\n",
    "    uri = 'sqlite:///' + db_path + db_id + '/' + db_id + '.sqlite'\n",
    "    db = SQLDatabase.from_uri(uri,  sample_rows_in_table_info=0)\n",
    "    return db\n",
    "\n",
    "\n",
    "def string_to_array(input):\n",
    "    return ast.literal_eval(input)\n",
    "\n",
    "def correctCase(llm_table_list, db_SQLDatabase):\n",
    "    corrected_tables = []\n",
    "    db_table_list = db_SQLDatabase.get_usable_table_names()\n",
    "    for table_name in llm_table_list:\n",
    "        for table in db_table_list:\n",
    "            if table_name.casefold() == table.casefold():\n",
    "                corrected_tables.append(table)\n",
    "    return corrected_tables\n",
    "\n",
    "def getPertinentSchema(llm_table_list, db_SQLDatabase):\n",
    "    return db_SQLDatabase.get_table_info(llm_table_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7121bd9-5af5-441e-a8de-3afb42101220",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_system = \"\"\"### Task\n",
    "        Given the following SQL tables, your job is to write SQLite queries given a userâ€™s request. Respond in one line.\n",
    "        {schema}\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "SQLite_System_Prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template= prompt_system\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3495fa8-4006-4d0b-8932-bf1f89bc3d03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "index is 0\n",
      "SELECT count(*) FROM singer\n",
      "SELECT COUNT(*) FROM singer\n",
      "\n",
      "index is 1\n",
      "SELECT count(*) FROM singer\n",
      "SELECT COUNT(*) FROM singer\n",
      "\n",
      "index is 2\n",
      "SELECT name ,  country ,  age FROM singer ORDER BY age DESC\n",
      "SELECT Name, Country, Age FROM singer ORDER BY Age DESC\n",
      "\n",
      "index is 3\n",
      "SELECT name ,  country ,  age FROM singer ORDER BY age DESC\n",
      "SELECT Name, Country, Age FROM singer ORDER BY Age DESC\n",
      "\n",
      "index is 4\n",
      "SELECT avg(age) ,  min(age) ,  max(age) FROM singer WHERE country  =  'France'\n",
      "SELECT AVG(Age) AS average_age, MIN(Age) AS min_age, MAX(Age) AS max_age FROM singer WHERE Country = 'France'\n",
      "\n",
      "index is 5\n",
      "SELECT avg(age) ,  min(age) ,  max(age) FROM singer WHERE country  =  'France'\n",
      "SELECT AVG(Age) AS average_age, MIN(Age) AS min_age, MAX(Age) AS max_age FROM singer WHERE Country = 'France'\n",
      "\n",
      "index is 6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m system_prompt \u001b[39m=\u001b[39m SQLite_System_Prompt\u001b[39m.\u001b[39mformat(schema \u001b[39m=\u001b[39m pertinent_schema)\n\u001b[1;32m     21\u001b[0m \u001b[39m#predicted_query, prompt_tokens, completion_tokens = base_model_generation(system_prompt, row['question'])\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m predicted_query, prompt_tokens, completion_tokens \u001b[39m=\u001b[39m GPT_generation(system_prompt, row[\u001b[39m'\u001b[39;49m\u001b[39mquestion\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     23\u001b[0m \u001b[39mprint\u001b[39m(row[\u001b[39m'\u001b[39m\u001b[39mgold_query\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     24\u001b[0m \u001b[39mprint\u001b[39m(predicted_query)\n",
      "Cell \u001b[0;32mIn[2], line 33\u001b[0m, in \u001b[0;36mGPT_generation\u001b[0;34m(system_prompt, user_prompt)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mGPT_generation\u001b[39m(system_prompt, user_prompt):\n\u001b[0;32m---> 33\u001b[0m   response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mchat\u001b[39m.\u001b[39;49mcompletions\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     34\u001b[0m     model\u001b[39m=\u001b[39;49m model_name ,\n\u001b[1;32m     35\u001b[0m     messages\u001b[39m=\u001b[39;49m[{\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39msystem\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: system_prompt},{\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: user_prompt}],\n\u001b[1;32m     36\u001b[0m     n \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[1;32m     37\u001b[0m     stream \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     38\u001b[0m     temperature\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m,\n\u001b[1;32m     39\u001b[0m     max_tokens\u001b[39m=\u001b[39;49m\u001b[39m600\u001b[39;49m,\n\u001b[1;32m     40\u001b[0m     top_p \u001b[39m=\u001b[39;49m \u001b[39m1.0\u001b[39;49m,\n\u001b[1;32m     41\u001b[0m     \n\u001b[1;32m     42\u001b[0m     frequency_penalty\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m,\n\u001b[1;32m     43\u001b[0m     presence_penalty\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m,\n\u001b[1;32m     44\u001b[0m   )\n\u001b[1;32m     45\u001b[0m   \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent, response\u001b[39m.\u001b[39musage\u001b[39m.\u001b[39mprompt_tokens, response\u001b[39m.\u001b[39musage\u001b[39m.\u001b[39mcompletion_tokens\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/openai/_utils/_utils.py:271\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m{\u001b[39;00mquote(missing[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    270\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 271\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/openai/resources/chat/completions.py:643\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39m@required_args\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    595\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    596\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    641\u001b[0m     timeout: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m httpx\u001b[39m.\u001b[39mTimeout \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m NotGiven \u001b[39m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    642\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ChatCompletion \u001b[39m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 643\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[1;32m    644\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m/chat/completions\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    645\u001b[0m         body\u001b[39m=\u001b[39;49mmaybe_transform(\n\u001b[1;32m    646\u001b[0m             {\n\u001b[1;32m    647\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmessages\u001b[39;49m\u001b[39m\"\u001b[39;49m: messages,\n\u001b[1;32m    648\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m: model,\n\u001b[1;32m    649\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfrequency_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: frequency_penalty,\n\u001b[1;32m    650\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunction_call\u001b[39;49m\u001b[39m\"\u001b[39;49m: function_call,\n\u001b[1;32m    651\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunctions\u001b[39;49m\u001b[39m\"\u001b[39;49m: functions,\n\u001b[1;32m    652\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogit_bias\u001b[39;49m\u001b[39m\"\u001b[39;49m: logit_bias,\n\u001b[1;32m    653\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogprobs\u001b[39;49m\u001b[39m\"\u001b[39;49m: logprobs,\n\u001b[1;32m    654\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmax_tokens\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_tokens,\n\u001b[1;32m    655\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mn\u001b[39;49m\u001b[39m\"\u001b[39;49m: n,\n\u001b[1;32m    656\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mpresence_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: presence_penalty,\n\u001b[1;32m    657\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mresponse_format\u001b[39;49m\u001b[39m\"\u001b[39;49m: response_format,\n\u001b[1;32m    658\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mseed\u001b[39;49m\u001b[39m\"\u001b[39;49m: seed,\n\u001b[1;32m    659\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstop\u001b[39;49m\u001b[39m\"\u001b[39;49m: stop,\n\u001b[1;32m    660\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream,\n\u001b[1;32m    661\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtemperature\u001b[39;49m\u001b[39m\"\u001b[39;49m: temperature,\n\u001b[1;32m    662\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtool_choice\u001b[39;49m\u001b[39m\"\u001b[39;49m: tool_choice,\n\u001b[1;32m    663\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtools\u001b[39;49m\u001b[39m\"\u001b[39;49m: tools,\n\u001b[1;32m    664\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_logprobs\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_logprobs,\n\u001b[1;32m    665\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_p\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_p,\n\u001b[1;32m    666\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m: user,\n\u001b[1;32m    667\u001b[0m             },\n\u001b[1;32m    668\u001b[0m             completion_create_params\u001b[39m.\u001b[39;49mCompletionCreateParams,\n\u001b[1;32m    669\u001b[0m         ),\n\u001b[1;32m    670\u001b[0m         options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[1;32m    671\u001b[0m             extra_headers\u001b[39m=\u001b[39;49mextra_headers, extra_query\u001b[39m=\u001b[39;49mextra_query, extra_body\u001b[39m=\u001b[39;49mextra_body, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    672\u001b[0m         ),\n\u001b[1;32m    673\u001b[0m         cast_to\u001b[39m=\u001b[39;49mChatCompletion,\n\u001b[1;32m    674\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    675\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mStream[ChatCompletionChunk],\n\u001b[1;32m    676\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/openai/_base_client.py:1112\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[1;32m   1099\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1100\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1107\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1108\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m   1109\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[1;32m   1110\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[1;32m   1111\u001b[0m     )\n\u001b[0;32m-> 1112\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/openai/_base_client.py:859\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    851\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    852\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    857\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    858\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m--> 859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m    860\u001b[0m         cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[1;32m    861\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    862\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    863\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m    864\u001b[0m         remaining_retries\u001b[39m=\u001b[39;49mremaining_retries,\n\u001b[1;32m    865\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/openai/_base_client.py:887\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    884\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mauth\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcustom_auth\n\u001b[1;32m    886\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 887\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49msend(\n\u001b[1;32m    888\u001b[0m         request,\n\u001b[1;32m    889\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_should_stream_response_body(request\u001b[39m=\u001b[39;49mrequest),\n\u001b[1;32m    890\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[1;32m    892\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mTimeoutException \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    893\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mEncountered httpx.TimeoutException\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/httpx/_client.py:915\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    907\u001b[0m follow_redirects \u001b[39m=\u001b[39m (\n\u001b[1;32m    908\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfollow_redirects\n\u001b[1;32m    909\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    910\u001b[0m     \u001b[39melse\u001b[39;00m follow_redirects\n\u001b[1;32m    911\u001b[0m )\n\u001b[1;32m    913\u001b[0m auth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 915\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_auth(\n\u001b[1;32m    916\u001b[0m     request,\n\u001b[1;32m    917\u001b[0m     auth\u001b[39m=\u001b[39;49mauth,\n\u001b[1;32m    918\u001b[0m     follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    919\u001b[0m     history\u001b[39m=\u001b[39;49m[],\n\u001b[1;32m    920\u001b[0m )\n\u001b[1;32m    921\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    922\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/httpx/_client.py:943\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    940\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(auth_flow)\n\u001b[1;32m    942\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 943\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_redirects(\n\u001b[1;32m    944\u001b[0m         request,\n\u001b[1;32m    945\u001b[0m         follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    946\u001b[0m         history\u001b[39m=\u001b[39;49mhistory,\n\u001b[1;32m    947\u001b[0m     )\n\u001b[1;32m    948\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/httpx/_client.py:980\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mrequest\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    978\u001b[0m     hook(request)\n\u001b[0;32m--> 980\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_single_request(request)\n\u001b[1;32m    981\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    982\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/httpx/_client.py:1016\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1011\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1012\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1013\u001b[0m     )\n\u001b[1;32m   1015\u001b[0m \u001b[39mwith\u001b[39;00m request_context(request\u001b[39m=\u001b[39mrequest):\n\u001b[0;32m-> 1016\u001b[0m     response \u001b[39m=\u001b[39m transport\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[1;32m   1018\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(response\u001b[39m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1020\u001b[0m response\u001b[39m.\u001b[39mrequest \u001b[39m=\u001b[39m request\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/httpx/_transports/default.py:231\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    218\u001b[0m req \u001b[39m=\u001b[39m httpcore\u001b[39m.\u001b[39mRequest(\n\u001b[1;32m    219\u001b[0m     method\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mmethod,\n\u001b[1;32m    220\u001b[0m     url\u001b[39m=\u001b[39mhttpcore\u001b[39m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m     extensions\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    229\u001b[0m )\n\u001b[1;32m    230\u001b[0m \u001b[39mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 231\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pool\u001b[39m.\u001b[39;49mhandle_request(req)\n\u001b[1;32m    233\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(resp\u001b[39m.\u001b[39mstream, typing\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m Response(\n\u001b[1;32m    236\u001b[0m     status_code\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mstatus,\n\u001b[1;32m    237\u001b[0m     headers\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mheaders,\n\u001b[1;32m    238\u001b[0m     stream\u001b[39m=\u001b[39mResponseStream(resp\u001b[39m.\u001b[39mstream),\n\u001b[1;32m    239\u001b[0m     extensions\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    240\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:268\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[39mwith\u001b[39;00m ShieldCancellation():\n\u001b[1;32m    267\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresponse_closed(status)\n\u001b[0;32m--> 268\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n\u001b[1;32m    269\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:251\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[39mraise\u001b[39;00m exc\n\u001b[1;32m    250\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 251\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[1;32m    252\u001b[0m \u001b[39mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    253\u001b[0m     \u001b[39m# The ConnectionNotAvailable exception is a special case, that\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     \u001b[39m# indicates we need to retry the request on a new connection.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[39m# might end up as an HTTP/2 connection, but which actually ends\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     \u001b[39m# up as HTTP/1.1.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pool_lock:\n\u001b[1;32m    261\u001b[0m         \u001b[39m# Maintain our position in the request queue, but reset the\u001b[39;00m\n\u001b[1;32m    262\u001b[0m         \u001b[39m# status so that the request becomes queued again.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connection\u001b[39m.\u001b[39mis_available():\n\u001b[1;32m    101\u001b[0m         \u001b[39mraise\u001b[39;00m ConnectionNotAvailable()\n\u001b[0;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connection\u001b[39m.\u001b[39;49mhandle_request(request)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/httpcore/_sync/http11.py:133\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[39mwith\u001b[39;00m Trace(\u001b[39m\"\u001b[39m\u001b[39mresponse_closed\u001b[39m\u001b[39m\"\u001b[39m, logger, request) \u001b[39mas\u001b[39;00m trace:\n\u001b[1;32m    132\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_response_closed()\n\u001b[0;32m--> 133\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/httpcore/_sync/http11.py:111\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[39mwith\u001b[39;00m Trace(\n\u001b[1;32m    104\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mreceive_response_headers\u001b[39m\u001b[39m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    105\u001b[0m ) \u001b[39mas\u001b[39;00m trace:\n\u001b[1;32m    106\u001b[0m     (\n\u001b[1;32m    107\u001b[0m         http_version,\n\u001b[1;32m    108\u001b[0m         status,\n\u001b[1;32m    109\u001b[0m         reason_phrase,\n\u001b[1;32m    110\u001b[0m         headers,\n\u001b[0;32m--> 111\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_response_headers(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    112\u001b[0m     trace\u001b[39m.\u001b[39mreturn_value \u001b[39m=\u001b[39m (\n\u001b[1;32m    113\u001b[0m         http_version,\n\u001b[1;32m    114\u001b[0m         status,\n\u001b[1;32m    115\u001b[0m         reason_phrase,\n\u001b[1;32m    116\u001b[0m         headers,\n\u001b[1;32m    117\u001b[0m     )\n\u001b[1;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m Response(\n\u001b[1;32m    120\u001b[0m     status\u001b[39m=\u001b[39mstatus,\n\u001b[1;32m    121\u001b[0m     headers\u001b[39m=\u001b[39mheaders,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m     },\n\u001b[1;32m    128\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/httpcore/_sync/http11.py:176\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    173\u001b[0m timeout \u001b[39m=\u001b[39m timeouts\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mread\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_event(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    177\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(event, h11\u001b[39m.\u001b[39mResponse):\n\u001b[1;32m    178\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/httpcore/_sync/http11.py:212\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    209\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mnext_event()\n\u001b[1;32m    211\u001b[0m \u001b[39mif\u001b[39;00m event \u001b[39mis\u001b[39;00m h11\u001b[39m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 212\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_network_stream\u001b[39m.\u001b[39;49mread(\n\u001b[1;32m    213\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mREAD_NUM_BYTES, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    214\u001b[0m     )\n\u001b[1;32m    216\u001b[0m     \u001b[39m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[39m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[39m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39m==\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mtheir_state \u001b[39m==\u001b[39m h11\u001b[39m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sock\u001b[39m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv(max_bytes)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/ssl.py:1259\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1255\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1256\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1257\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1258\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1259\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(buflen)\n\u001b[1;32m   1260\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1261\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/ssl.py:1132\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m)\n\u001b[1;32m   1133\u001b[0m \u001b[39mexcept\u001b[39;00m SSLError \u001b[39mas\u001b[39;00m x:\n\u001b[1;32m   1134\u001b[0m     \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m SSL_ERROR_EOF \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    CODEX = load_data_json(INPUT_FILE)\n",
    "    for index, row in enumerate(CODEX):\n",
    "        print(\"\")\n",
    "        print(f\"index is {index}\")\n",
    "        if not row['error_encountered']:\n",
    "            db_SQLDatabase = getSQLDatabase(row['db_id'])\n",
    "            error_encountered = False\n",
    "            error = None\n",
    "            try:\n",
    "                llm_table_list = string_to_array(row['table_list'])\n",
    "                corrected_llm_table_list = correctCase(llm_table_list, db_SQLDatabase)\n",
    "            except Exception as e:\n",
    "                error = e\n",
    "                error_encountered = True\n",
    "            if not error_encountered:\n",
    "                pertinent_schema = getPertinentSchema(corrected_llm_table_list, db_SQLDatabase)\n",
    "                if pertinent_schema:\n",
    "                    try:                    \n",
    "                        system_prompt = SQLite_System_Prompt.format(schema = pertinent_schema)\n",
    "                        #predicted_query, prompt_tokens, completion_tokens = base_model_generation(system_prompt, row['question'])\n",
    "                        predicted_query, prompt_tokens, completion_tokens = GPT_generation(system_prompt, row['question'])\n",
    "                        print(row['gold_query'])\n",
    "                        print(predicted_query)\n",
    "                    except Exception as e:\n",
    "                        print('e')\n",
    "                        error = e\n",
    "                        error_encountered = True\n",
    "            if not error_encountered:\n",
    "                row.update({'predicted_query': predicted_query, 'prompt_tokens':prompt_tokens, 'completion_tokens':completion_tokens})\n",
    "            else:\n",
    "                row['error_encountered'] = True\n",
    "                row['error_type'] = type(error).__name__\n",
    "                row['error_message'] = str(error)\n",
    "            \n",
    "    OUTPUT_DIR = '/home/llmuser/models/results/'\n",
    "    OUTPUT_FILE_DIFF = 'test.json'\n",
    "    OUTPUT_PATH = os.path.join(OUTPUT_DIR, OUTPUT_FILE_DIFF)\n",
    "    # Save the object to a JSON file\n",
    "    with open(OUTPUT_PATH, 'w') as json_file:\n",
    "        json.dump(CODEX, json_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "566fbdd4",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70bfabe6-3a70-416f-94f0-63e2115c0642",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = '/home/llmuser/models/results/all-tables-pred-mixtral-sqlcoder-7b-2.json'\n",
    "\n",
    "def getdbPath(db_id):\n",
    "    # Modificar el PATH para donde este la base de datos\n",
    "    db_path = SPIDER_DB_DIR\n",
    "    db_uri = db_path + db_id + '/' + db_id + '.sqlite'\n",
    "    return db_uri\n",
    "\n",
    "def queryDB(database, SQL_query):\n",
    "    conn = sqlite3.connect(database)\n",
    "    # Create a cursor object to execute SQL queries\n",
    "    cursor = conn.cursor()\n",
    "    # Create a table\n",
    "    cursor.execute(\"PRAGMA case_sensitive_like = OFF\")\n",
    "    cursor.execute(SQL_query)\n",
    "    results = cursor.fetchall()\n",
    "    return results\n",
    "    # Close the cursor and connection\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "def correctQuery(CODEX):\n",
    "    for row in CODEX:\n",
    "        if not row['error_encountered']:\n",
    "            row['predicted_query'] = row['predicted_query'].replace('ILIKE', 'LIKE', -1)\n",
    "            row['predicted_query'] = row['predicted_query'].replace('[/SQL]', '', -1)\n",
    "\n",
    "def evaluatePredict(CODEX):\n",
    "    count = 0\n",
    "    for row in CODEX:\n",
    "        predict_query_valid = True\n",
    "        if not row['error_encountered']:\n",
    "            db = getdbPath(row['db_id'])\n",
    "            error_encountered = False\n",
    "            error = None\n",
    "            error_type = None\n",
    "            try:\n",
    "                goldQueryValue =  queryDB(db, row['gold_query'])\n",
    "            except Exception as e:\n",
    "                error_encountered = True\n",
    "                error_type = 'Cannot_Query_Gold'\n",
    "                error_message = str(e)\n",
    "                predict_query_valid = False\n",
    "                goldQueryValue = None\n",
    "            pred_query = row['predicted_query']\n",
    "            if not error_encountered:\n",
    "                try:\n",
    "                    predQueryValue = queryDB(db, pred_query)\n",
    "                except Exception as e:\n",
    "                    error_encountered = True\n",
    "                    error_type = 'Cannot_Query_Pred'\n",
    "                    error_message = str(e)\n",
    "                    predQueryValue = None\n",
    "            if not error_encountered:\n",
    "                if goldQueryValue == predQueryValue :\n",
    "                    predict_success = True\n",
    "                else:\n",
    "                    predict_success = False\n",
    "                    error_encountered = True\n",
    "                    error_type = 'Gold_Predict_Missmatch'\n",
    "                    error_message = None\n",
    "            row.update({'predict_success':predict_success, 'gold_result':goldQueryValue, 'predict_result': predQueryValue,'predict_query_valid':predict_query_valid})\n",
    "            if error_encountered:\n",
    "                row['error_encountered'] = error_encountered\n",
    "                row['error_type'] = error_type\n",
    "                row['error_message'] = error_message\n",
    "    return CODEX\n",
    "\n",
    "\n",
    "CODEX = load_data_json(OUTPUT_DIR)\n",
    "\n",
    "correctQuery(CODEX)\n",
    "CODEX_OUT = evaluatePredict(CODEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7b7c15c-dbaf-480e-a7b3-eff481666010",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = '/home/llmuser/models/results/'\n",
    "\n",
    "OUTPUT_FILE_DIFF = 'all-tables-pred-mixtral-sqlcoder-7b-2-final-results.json'\n",
    "\n",
    "OUTPUT_PATH = os.path.join(OUTPUT_DIR, OUTPUT_FILE_DIFF)\n",
    "\n",
    "# Save the object to a JSON file\n",
    "with open(OUTPUT_PATH, 'w') as json_file:\n",
    "    json.dump(CODEX_OUT, json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
