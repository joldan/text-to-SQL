{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "def7bba7-8ede-4529-95b1-5799468dcfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/llmuser', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/home/llmuser/.local/lib/python3.10/site-packages', '/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n",
    "\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.utilities import SQLDatabase\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import ast\n",
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5572347-000f-4789-bd19-e5c6808c7072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks support token-wise streaming\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ec75acb-a420-4e78-b87b-753c6f4e0000",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_init_cublas: GGML_CUDA_FORCE_MMQ:   no\n",
      "ggml_init_cublas: CUDA_USE_TENSOR_CORES: yes\n",
      "ggml_init_cublas: found 6 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce RTX 3060 Ti, compute capability 8.6, VMM: yes\n",
      "  Device 1: NVIDIA GeForce RTX 3060 Ti, compute capability 8.6, VMM: yes\n",
      "  Device 2: NVIDIA GeForce RTX 2060, compute capability 7.5, VMM: yes\n",
      "  Device 3: NVIDIA GeForce RTX 2060, compute capability 7.5, VMM: yes\n",
      "  Device 4: NVIDIA GeForce RTX 2060, compute capability 7.5, VMM: yes\n",
      "  Device 5: NVIDIA GeForce RTX 2060, compute capability 7.5, VMM: yes\n",
      "llama_model_loader: loaded meta data with 25 key-value pairs and 995 tensors from models/mixtral-8x7b-v0.1.Q5_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = mistralai_mixtral-8x7b-v0.1\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:                         llama.expert_count u32              = 8\n",
      "llama_model_loader: - kv  10:                    llama.expert_used_count u32              = 2\n",
      "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  12:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  13:                          general.file_type u32              = 17\n",
      "llama_model_loader: - kv  14:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  16:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  17:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  20:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  21:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  22:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  23:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  24:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type  f16:   32 tensors\n",
      "llama_model_loader: - type q8_0:   64 tensors\n",
      "llama_model_loader: - type q5_K:  833 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 8\n",
      "llm_load_print_meta: n_expert_used    = 2\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 1000000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Medium\n",
      "llm_load_print_meta: model params     = 46.70 B\n",
      "llm_load_print_meta: model size       = 30.02 GiB (5.52 BPW) \n",
      "llm_load_print_meta: general.name     = mistralai_mixtral-8x7b-v0.1\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    2.66 MiB\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =    85.94 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  6682.16 MiB\n",
      "llm_load_tensors:      CUDA1 buffer size =  6682.16 MiB\n",
      "llm_load_tensors:      CUDA2 buffer size =  4772.97 MiB\n",
      "llm_load_tensors:      CUDA3 buffer size =  4772.97 MiB\n",
      "llm_load_tensors:      CUDA4 buffer size =  4772.97 MiB\n",
      "llm_load_tensors:      CUDA5 buffer size =  2966.34 MiB\n",
      "....................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 10000\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =   273.44 MiB\n",
      "llama_kv_cache_init:      CUDA1 KV buffer size =   273.44 MiB\n",
      "llama_kv_cache_init:      CUDA2 KV buffer size =   195.31 MiB\n",
      "llama_kv_cache_init:      CUDA3 KV buffer size =   195.31 MiB\n",
      "llama_kv_cache_init:      CUDA4 KV buffer size =   195.31 MiB\n",
      "llama_kv_cache_init:      CUDA5 KV buffer size =   117.19 MiB\n",
      "llama_new_context_with_model: KV self size  = 1250.00 MiB, K (f16):  625.00 MiB, V (f16):  625.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host input buffer size   =     0.47 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =    11.97 MiB\n",
      "llama_new_context_with_model:      CUDA1 compute buffer size =    12.11 MiB\n",
      "llama_new_context_with_model:      CUDA2 compute buffer size =    12.11 MiB\n",
      "llama_new_context_with_model:      CUDA3 compute buffer size =    12.11 MiB\n",
      "llama_new_context_with_model:      CUDA4 compute buffer size =    12.11 MiB\n",
      "llama_new_context_with_model:      CUDA5 compute buffer size =    12.11 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =     0.14 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 13\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 0 | ARM_FMA = 0 | F16C = 0 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n",
      "Model metadata: {'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '17', 'general.architecture': 'llama', 'llama.rope.freq_base': '1000000.000000', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'llama.expert_count': '8', 'llama.context_length': '32768', 'general.name': 'mistralai_mixtral-8x7b-v0.1', 'llama.expert_used_count': '2'}\n"
     ]
    }
   ],
   "source": [
    "local_llm = LlamaCpp(\n",
    "    model_path=\"models/mixtral-8x7b-v0.1.Q5_K_M.gguf\",\n",
    "    temperature=0.0,\n",
    "    n_gpu_layers=-1,\n",
    "    max_tokens=600,\n",
    "    n_ctx=10000,\n",
    "    top_p=1,\n",
    "    callback_manager=callback_manager,\n",
    "    stop = [\"Q:\"],\n",
    "    verbose=True,  # Verbose is required to pass to the callback manager\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69d03245-f4f5-46d7-955a-bfdcb624ef5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#----------------------------------------------------prompts-----------------------------------------------\n",
    "schema_linking_prompt = '''Table advisor, columns = [*,s_ID,i_ID]\n",
    "Table classroom, columns = [*,building,room_number,capacity]\n",
    "Table course, columns = [*,course_id,title,dept_name,credits]\n",
    "Table department, columns = [*,dept_name,building,budget]\n",
    "Table instructor, columns = [*,ID,name,dept_name,salary]\n",
    "Table prereq, columns = [*,course_id,prereq_id]\n",
    "Table section, columns = [*,course_id,sec_id,semester,year,building,room_number,time_slot_id]\n",
    "Table student, columns = [*,ID,name,dept_name,tot_cred]\n",
    "Table takes, columns = [*,ID,course_id,sec_id,semester,year,grade]\n",
    "Table teaches, columns = [*,ID,course_id,sec_id,semester,year]\n",
    "Table time_slot, columns = [*,time_slot_id,day,start_hr,start_min,end_hr,end_min]\n",
    "Foreign_keys = [course.dept_name = department.dept_name,instructor.dept_name = department.dept_name,section.building = classroom.building,section.room_number = classroom.room_number,section.course_id = course.course_id,teaches.ID = instructor.ID,teaches.course_id = section.course_id,teaches.sec_id = section.sec_id,teaches.semester = section.semester,teaches.year = section.year,student.dept_name = department.dept_name,takes.ID = student.ID,takes.course_id = section.course_id,takes.sec_id = section.sec_id,takes.semester = section.semester,takes.year = section.year,advisor.s_ID = student.ID,advisor.i_ID = instructor.ID,prereq.prereq_id = course.course_id,prereq.course_id = course.course_id]\n",
    "Q: \"Find the buildings which have rooms with capacity more than 50.\"\n",
    "A: Let’s think step by step. In the question \"Find the buildings which have rooms with capacity more than 50.\", we are asked:\n",
    "\"the buildings which have rooms\" so we need column = [classroom.capacity]\n",
    "\"rooms with capacity\" so we need column = [classroom.building]\n",
    "Based on the columns and tables, we need these Foreign_keys = [].\n",
    "Based on the tables, columns, and Foreign_keys, The set of possible cell values are = [50]. So the Schema_links are:\n",
    "Schema_links: [classroom.building,classroom.capacity,50]\n",
    "\n",
    "Table department, columns = [*,Department_ID,Name,Creation,Ranking,Budget_in_Billions,Num_Employees]\n",
    "Table head, columns = [*,head_ID,name,born_state,age]\n",
    "Table management, columns = [*,department_ID,head_ID,temporary_acting]\n",
    "Foreign_keys = [management.head_ID = head.head_ID,management.department_ID = department.Department_ID]\n",
    "Q: \"How many heads of the departments are older than 56 ?\"\n",
    "A: Let’s think step by step. In the question \"How many heads of the departments are older than 56 ?\", we are asked:\n",
    "\"How many heads of the departments\" so we need column = [head.*]\n",
    "\"older\" so we need column = [head.age]\n",
    "Based on the columns and tables, we need these Foreign_keys = [].\n",
    "Based on the tables, columns, and Foreign_keys, The set of possible cell values are = [56]. So the Schema_links are:\n",
    "Schema_links: [head.*,head.age,56]\n",
    "\n",
    "Table department, columns = [*,Department_ID,Name,Creation,Ranking,Budget_in_Billions,Num_Employees]\n",
    "Table head, columns = [*,head_ID,name,born_state,age]\n",
    "Table management, columns = [*,department_ID,head_ID,temporary_acting]\n",
    "Foreign_keys = [management.head_ID = head.head_ID,management.department_ID = department.Department_ID]\n",
    "Q: \"what are the distinct creation years of the departments managed by a secretary born in state 'Alabama'?\"\n",
    "A: Let’s think step by step. In the question \"what are the distinct creation years of the departments managed by a secretary born in state 'Alabama'?\", we are asked:\n",
    "\"distinct creation years of the departments\" so we need column = [department.Creation]\n",
    "\"departments managed by\" so we need column = [management.department_ID]\n",
    "\"born in\" so we need column = [head.born_state]\n",
    "Based on the columns and tables, we need these Foreign_keys = [department.Department_ID = management.department_ID,management.head_ID = head.head_ID].\n",
    "Based on the tables, columns, and Foreign_keys, The set of possible cell values are = ['Alabama']. So the Schema_links are:\n",
    "Schema_links: [department.Creation,department.Department_ID = management.department_ID,head.head_ID = management.head_ID,head.born_state,'Alabama']\n",
    "\n",
    "'''\n",
    "classification_prompt = '''Q: \"Find the buildings which have rooms with capacity more than 50.\"\n",
    "schema_links: [classroom.building,classroom.capacity,50]\n",
    "A: Let’s think step by step. The SQL query for the question \"Find the buildings which have rooms with capacity more than 50.\" needs these tables = [classroom], so we don't need JOIN.\n",
    "Plus, it doesn't require nested queries with (INTERSECT, UNION, EXCEPT, IN, NOT IN), and we need the answer to the questions = [\"\"].\n",
    "So, we don't need JOIN and don't need nested queries, then the the SQL query can be classified as \"EASY\".\n",
    "Label: \"EASY\"\n",
    "\n",
    "Q: \"What are the names of all instructors who advise students in the math depart sorted by total credits of the student.\"\n",
    "schema_links: [advisor.i_id = instructor.id,advisor.s_id = student.id,instructor.name,student.dept_name,student.tot_cred,math]\n",
    "A: Let’s think step by step. The SQL query for the question \"What are the names of all instructors who advise students in the math depart sorted by total credits of the student.\" needs these tables = [advisor,instructor,student], so we need JOIN.\n",
    "Plus, it doesn't need nested queries with (INTERSECT, UNION, EXCEPT, IN, NOT IN), and we need the answer to the questions = [\"\"].\n",
    "So, we need JOIN and don't need nested queries, then the the SQL query can be classified as \"NON-NESTED\".\n",
    "Label: \"NON-NESTED\"\n",
    "\n",
    "Q: \"Find the room number of the rooms which can sit 50 to 100 students and their buildings.\"\n",
    "schema_links: [classroom.building,classroom.room_number,classroom.capacity,50,100]\n",
    "A: Let’s think step by step. The SQL query for the question \"Find the room number of the rooms which can sit 50 to 100 students and their buildings.\" needs these tables = [classroom], so we don't need JOIN.\n",
    "Plus, it doesn't require nested queries with (INTERSECT, UNION, EXCEPT, IN, NOT IN), and we need the answer to the questions = [\"\"].\n",
    "So, we don't need JOIN and don't need nested queries, then the the SQL query can be classified as \"EASY\".\n",
    "Label: \"EASY\"\n",
    "\n",
    "Q: \"How many courses that do not have prerequisite?\"\n",
    "schema_links: [course.*,course.course_id = prereq.course_id]\n",
    "A: Let’s think step by step. The SQL query for the question \"How many courses that do not have prerequisite?\" needs these tables = [course,prereq], so we need JOIN.\n",
    "Plus, it requires nested queries with (INTERSECT, UNION, EXCEPT, IN, NOT IN), and we need the answer to the questions = [\"Which courses have prerequisite?\"].\n",
    "So, we need JOIN and need nested queries, then the the SQL query can be classified as \"NESTED\".\n",
    "Label: \"NESTED\"\n",
    "\n",
    "Q: \"Find the title of course that is provided by both Statistics and Psychology departments.\"\n",
    "schema_links: [course.title,course.dept_name,Statistics,Psychology]\n",
    "A: Let’s think step by step. The SQL query for the question \"Find the title of course that is provided by both Statistics and Psychology departments.\" needs these tables = [course], so we don't need JOIN.\n",
    "Plus, it requires nested queries with (INTERSECT, UNION, EXCEPT, IN, NOT IN), and we need the answer to the questions = [\"Find the titles of courses that is provided by Psychology departments\"].\n",
    "So, we don't need JOIN and need nested queries, then the the SQL query can be classified as \"NESTED\".\n",
    "Label: \"NESTED\"\n",
    "\n",
    "Q: \"What is the name of the instructor who advises the student with the greatest number of total credits?\"\n",
    "schema_links: [advisor.i_id = instructor.id,advisor.s_id = student.id,instructor.name,student.tot_cred ]\n",
    "A: Let’s think step by step. The SQL query for the question \"What is the name of the instructor who advises the student with the greatest number of total credits?\" needs these tables = [advisor,instructor,student], so we need JOIN.\n",
    "Plus, it doesn't need nested queries with (INTERSECT, UNION, EXCEPT, IN, NOT IN), and we need the answer to the questions = [\"\"].\n",
    "So, we need JOIN and don't need nested queries, then the the SQL query can be classified as \"NON-NESTED\".\n",
    "Label: \"NON-NESTED\"\n",
    "\n",
    "'''\n",
    "\n",
    "easy_prompt = '''Q: \"Find the buildings which have rooms with capacity more than 50.\"\n",
    "Schema_links: [classroom.building,classroom.capacity,50]\n",
    "SQL: SELECT DISTINCT building FROM classroom WHERE capacity  >  50\n",
    "\n",
    "Q: \"Find the room number of the rooms which can sit 50 to 100 students and their buildings.\"\n",
    "Schema_links: [classroom.building,classroom.room_number,classroom.capacity,50,100]\n",
    "SQL: SELECT building ,  room_number FROM classroom WHERE capacity BETWEEN 50 AND 100\n",
    "\n",
    "Q: \"Give the name of the student in the History department with the most credits.\"\n",
    "Schema_links: [student.name,student.dept_name,student.tot_cred,History]\n",
    "SQL: SELECT name FROM student WHERE dept_name  =  'History' ORDER BY tot_cred DESC LIMIT 1\n",
    "\n",
    "\n",
    "'''\n",
    "medium_prompt = '''Q: \"Find the total budgets of the Marketing or Finance department.\"\n",
    "Schema_links: [department.budget,department.dept_name,Marketing,Finance]\n",
    "A: Let’s think step by step. For creating the SQL for the given question, we need to join these tables = []. First, create an intermediate representation, then use it to construct the SQL query.\n",
    "Intermediate_representation: select sum(department.budget) from department  where  department.dept_name = \\\"Marketing\\\"  or  department.dept_name = \\\"Finance\\\"\n",
    "SQL: SELECT sum(budget) FROM department WHERE dept_name  =  'Marketing' OR dept_name  =  'Finance'\n",
    "\n",
    "Q: \"Find the name and building of the department with the highest budget.\"\n",
    "Schema_links: [department.budget,department.dept_name,department.building]\n",
    "A: Let’s think step by step. For creating the SQL for the given question, we need to join these tables = []. First, create an intermediate representation, then use it to construct the SQL query.\n",
    "Intermediate_representation: select department.dept_name , department.building from department  order by department.budget desc limit 1\n",
    "SQL: SELECT dept_name ,  building FROM department ORDER BY budget DESC LIMIT 1\n",
    "\n",
    "Q: \"What is the name and building of the departments whose budget is more than the average budget?\"\n",
    "Schema_links: [department.budget,department.dept_name,department.building]\n",
    "A: Let’s think step by step. For creating the SQL for the given question, we need to join these tables = []. First, create an intermediate representation, then use it to construct the SQL query.\n",
    "Intermediate_representation:  select department.dept_name , department.building from department  where  @.@ > avg ( department.budget ) \n",
    "SQL: SELECT dept_name ,  building FROM department WHERE budget  >  (SELECT avg(budget) FROM department)\n",
    "\n",
    "'''\n",
    "hard_prompt = '''Q: \"Find the title of courses that have two prerequisites?\"\n",
    "Schema_links: [course.title,course.course_id = prereq.course_id]\n",
    "A: Let's think step by step. \"Find the title of courses that have two prerequisites?\" can be solved by knowing the answer to the following sub-question \"What are the titles for courses with two prerequisites?\".\n",
    "The SQL query for the sub-question \"What are the titles for courses with two prerequisites?\" is SELECT T1.title FROM course AS T1 JOIN prereq AS T2 ON T1.course_id  =  T2.course_id GROUP BY T2.course_id HAVING count(*)  =  2\n",
    "So, the answer to the question \"Find the title of courses that have two prerequisites?\" is =\n",
    "Intermediate_representation: select course.title from course  where  count ( prereq.* )  = 2  group by prereq.course_id\n",
    "SQL: SELECT T1.title FROM course AS T1 JOIN prereq AS T2 ON T1.course_id  =  T2.course_id GROUP BY T2.course_id HAVING count(*)  =  2\n",
    "\n",
    "Q: \"Find the name and building of the department with the highest budget.\"\n",
    "Schema_links: [department.dept_name,department.building,department.budget]\n",
    "A: Let's think step by step. \"Find the name and building of the department with the highest budget.\" can be solved by knowing the answer to the following sub-question \"What is the department name and corresponding building for the department with the greatest budget?\".\n",
    "The SQL query for the sub-question \"What is the department name and corresponding building for the department with the greatest budget?\" is SELECT dept_name ,  building FROM department ORDER BY budget DESC LIMIT 1\n",
    "So, the answer to the question \"Find the name and building of the department with the highest budget.\" is =\n",
    "Intermediate_representation: select department.dept_name , department.building from department  order by department.budget desc limit 1\n",
    "SQL: SELECT dept_name ,  building FROM department ORDER BY budget DESC LIMIT 1\n",
    "\n",
    "Q: \"Find the title, credit, and department name of courses that have more than one prerequisites?\"\n",
    "Schema_links: [course.title,course.credits,course.dept_name,course.course_id = prereq.course_id]\n",
    "A: Let's think step by step. \"Find the title, credit, and department name of courses that have more than one prerequisites?\" can be solved by knowing the answer to the following sub-question \"What is the title, credit value, and department name for courses with more than one prerequisite?\".\n",
    "The SQL query for the sub-question \"What is the title, credit value, and department name for courses with more than one prerequisite?\" is SELECT T1.title ,  T1.credits , T1.dept_name FROM course AS T1 JOIN prereq AS T2 ON T1.course_id  =  T2.course_id GROUP BY T2.course_id HAVING count(*)  >  1\n",
    "So, the answer to the question \"Find the name and building of the department with the highest budget.\" is =\n",
    "Intermediate_representation: select course.title , course.credits , course.dept_name from course  where  count ( prereq.* )  > 1  group by prereq.course_id \n",
    "SQL: SELECT T1.title ,  T1.credits , T1.dept_name FROM course AS T1 JOIN prereq AS T2 ON T1.course_id  =  T2.course_id GROUP BY T2.course_id HAVING count(*)  >  1\n",
    "\n",
    "'''\n",
    "#----------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acc62b10-a319-421e-9d20-c342a9a1bf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATASET_SCHEMA = '/home/llmuser/models/datasets/spider-2/tables.json'\n",
    "DATASET = '/home/llmuser/models/datasets/spider-2/dev.json'\n",
    "OUTPUT_FILE = '/home/llmuser/models/results/DIN-SQL-results'\n",
    "\n",
    "\n",
    "OUTPUT_DIR = '/home/llmuser/models/results/'\n",
    "SPIDER_DB_DIR = '/home/llmuser/models/datasets/spider-2/database/' #the path were all databases exist\n",
    "\n",
    "def load_data(DATASET):\n",
    "    return pd.read_json(DATASET)\n",
    "\n",
    "def hard_prompt_maker(test_sample_text,database,schema_links,sub_questions):\n",
    "  instruction = \"# Use the intermediate representation and the schema links to generate the SQL queries for each of the questions.\\n\"\n",
    "  fields = find_fields_MYSQL_like(\"college_2\")\n",
    "  fields += \"Foreign_keys = \" + find_foreign_keys_MYSQL_like(\"college_2\") + '\\n'\n",
    "  fields += find_fields_MYSQL_like(database)\n",
    "  fields += \"Foreign_keys = \" + find_foreign_keys_MYSQL_like(database) + '\\n'\n",
    "  stepping = f'''\\nA: Let's think step by step. \"{test_sample_text}\" can be solved by knowing the answer to the following sub-question \"{sub_questions}\".'''\n",
    "  fields += \"\\n\"\n",
    "  prompt = instruction +fields + hard_prompt + 'Q: \"' + test_sample_text + '\"' + '\\nschema_links: ' + schema_links + stepping +'\\nThe SQL query for the sub-question\"'\n",
    "  return prompt\n",
    "def medium_prompt_maker(test_sample_text,database,schema_links):\n",
    "  instruction = \"# Use the the schema links and Intermediate_representation to generate the SQL queries for each of the questions.\\n\"\n",
    "  fields = find_fields_MYSQL_like(\"college_2\")\n",
    "  fields += \"Foreign_keys = \" + find_foreign_keys_MYSQL_like(\"college_2\") + '\\n'\n",
    "  fields += find_fields_MYSQL_like(database)\n",
    "  fields += \"Foreign_keys = \" + find_foreign_keys_MYSQL_like(database) + '\\n'\n",
    "  fields += \"\\n\"\n",
    "  prompt = instruction +fields + medium_prompt + 'Q: \"' + test_sample_text + '\\nSchema_links: ' + schema_links + '\\nA: Let’s think step by step.'\n",
    "  return prompt\n",
    "def easy_prompt_maker(test_sample_text,database,schema_links):\n",
    "  instruction = \"# Use the the schema links to generate the SQL queries for each of the questions.\\n\"\n",
    "  fields = find_fields_MYSQL_like(\"college_2\")\n",
    "  fields += find_fields_MYSQL_like(database)\n",
    "  fields += \"\\n\"\n",
    "  prompt = instruction +fields + easy_prompt + 'Q: \"' + test_sample_text + '\\nSchema_links: ' + schema_links + '\\nSQL:'\n",
    "  return prompt\n",
    "def classification_prompt_maker(test_sample_text,database,schema_links):\n",
    "  instruction = \"# For the given question, classify it as EASY, NON-NESTED, or NESTED based on nested queries and JOIN.\\n\"\n",
    "  instruction += \"\\nif need nested queries: predict NESTED\\n\"\n",
    "  instruction += \"elif need JOIN and don't need nested queries: predict NON-NESTED\\n\"\n",
    "  instruction += \"elif don't need JOIN and don't need nested queries: predict EASY\\n\\n\"\n",
    "  fields = find_fields_MYSQL_like(\"college_2\")\n",
    "  fields += \"Foreign_keys = \" + find_foreign_keys_MYSQL_like(\"college_2\") + '\\n'\n",
    "  fields += find_fields_MYSQL_like(database)\n",
    "  fields += \"Foreign_keys = \" + find_foreign_keys_MYSQL_like(database) + '\\n'\n",
    "  fields += \"\\n\"\n",
    "  prompt = instruction + fields + classification_prompt + 'Q: \"' + test_sample_text + '\\nschema_links: ' + schema_links + '\\nA: Let’s think step by step.'\n",
    "  return prompt\n",
    "def schema_linking_prompt_maker(test_sample_text,database):\n",
    "  instruction = \"# Find the schema_links for generating SQL queries for each question based on the database schema and Foreign keys.\\n\"\n",
    "  fields = find_fields_MYSQL_like(database)\n",
    "  foreign_keys = \"Foreign_keys = \" + find_foreign_keys_MYSQL_like(database) + '\\n'\n",
    "  prompt = instruction + schema_linking_prompt + fields +foreign_keys+ 'Q: \"' + test_sample_text + \"\"\"\"\\nA: Let’s think step by step.\"\"\"\n",
    "  return prompt\n",
    "def find_foreign_keys_MYSQL_like(db_name):\n",
    "  df = spider_foreign[spider_foreign['Database name'] == db_name]\n",
    "  output = \"[\"\n",
    "  for index, row in df.iterrows():\n",
    "    output += row['First Table Name'] + '.' + row['First Table Foreign Key'] + \" = \" + row['Second Table Name'] + '.' + row['Second Table Foreign Key'] + ','\n",
    "  output= output[:-1] + \"]\"\n",
    "  return output\n",
    "def find_fields_MYSQL_like(db_name):\n",
    "  df = spider_schema[spider_schema['Database name'] == db_name]\n",
    "  df = df.groupby(' Table Name')\n",
    "  output = \"\"\n",
    "  for name, group in df:\n",
    "    output += \"Table \" +name+ ', columns = ['\n",
    "    for index, row in group.iterrows():\n",
    "      output += row[\" Field Name\"]+','\n",
    "    output = output[:-1]\n",
    "    output += \"]\\n\"\n",
    "  return output\n",
    "def find_primary_keys_MYSQL_like(db_name):\n",
    "  df = spider_primary[spider_primary['Database name'] == db_name]\n",
    "  output = \"[\"\n",
    "  for index, row in df.iterrows():\n",
    "    output += row['Table Name'] + '.' + row['Primary Key'] +','\n",
    "  output = output[:-1]\n",
    "  output += \"]\\n\"\n",
    "  return output\n",
    "def creatiing_schema(DATASET_JSON):\n",
    "    schema_df = pd.read_json(DATASET_JSON)\n",
    "    schema_df = schema_df.drop(['column_names','table_names'], axis=1)\n",
    "    schema = []\n",
    "    f_keys = []\n",
    "    p_keys = []\n",
    "    for index, row in schema_df.iterrows():\n",
    "        tables = row['table_names_original']\n",
    "        col_names = row['column_names_original']\n",
    "        col_types = row['column_types']\n",
    "        foreign_keys = row['foreign_keys']\n",
    "        primary_keys = row['primary_keys']\n",
    "        for col, col_type in zip(col_names, col_types):\n",
    "            index, col_name = col\n",
    "            if index == -1:\n",
    "                for table in tables:\n",
    "                    schema.append([row['db_id'], table, '*', 'text'])\n",
    "            else:\n",
    "                schema.append([row['db_id'], tables[index], col_name, col_type])\n",
    "        for primary_key in primary_keys:\n",
    "            index, column = col_names[primary_key]\n",
    "            p_keys.append([row['db_id'], tables[index], column])\n",
    "        for foreign_key in foreign_keys:\n",
    "            first, second = foreign_key\n",
    "            first_index, first_column = col_names[first]\n",
    "            second_index, second_column = col_names[second]\n",
    "            f_keys.append([row['db_id'], tables[first_index], tables[second_index], first_column, second_column])\n",
    "    spider_schema = pd.DataFrame(schema, columns=['Database name', ' Table Name', ' Field Name', ' Type'])\n",
    "    spider_primary = pd.DataFrame(p_keys, columns=['Database name', 'Table Name', 'Primary Key'])\n",
    "    spider_foreign = pd.DataFrame(f_keys,\n",
    "                        columns=['Database name', 'First Table Name', 'Second Table Name', 'First Table Foreign Key',\n",
    "                                 'Second Table Foreign Key'])\n",
    "    return spider_schema,spider_primary,spider_foreign\n",
    "def debuger(test_sample_text,database,sql):\n",
    "  instruction = \"\"\"#### For the given question, use the provided tables, columns, foreign keys, and primary keys to fix the given SQLite SQL QUERY for any issues. If there are any problems, fix them. If there are no issues, return the SQLite SQL QUERY as is.\n",
    "#### Use the following instructions for fixing the SQL QUERY:\n",
    "1) Use the database values that are explicitly mentioned in the question.\n",
    "2) Pay attention to the columns that are used for the JOIN by using the Foreign_keys.\n",
    "3) Use DESC and DISTINCT when needed.\n",
    "4) Pay attention to the columns that are used for the GROUP BY statement.\n",
    "5) Pay attention to the columns that are used for the SELECT statement.\n",
    "6) Only change the GROUP BY clause when necessary (Avoid redundant columns in GROUP BY).\n",
    "7) Use GROUP BY on one column only.\n",
    "\n",
    "\"\"\"\n",
    "  fields = find_fields_MYSQL_like(database)\n",
    "  fields += \"Foreign_keys = \" + find_foreign_keys_MYSQL_like(database) + '\\n'\n",
    "  fields += \"Primary_keys = \" + find_primary_keys_MYSQL_like(database)\n",
    "  prompt = instruction + fields+ '#### Question: ' + test_sample_text + '\\n#### SQLite SQL QUERY\\n' + sql +'\\n#### SQLite FIXED SQL QUERY\\nSELECT'\n",
    "  return prompt\n",
    "\n",
    "def local_generation(prompt):\n",
    "    local_llm.stop = [\"Q:\"]\n",
    "    local_llm.max_tokens=600\n",
    "    return local_llm(prompt)    \n",
    "\n",
    "def local_debug(prompt):\n",
    "    local_llm.stop = [\"#\", \";\",\"\\n\\n\"]\n",
    "    local_llm.max_tokens=350\n",
    "    return local_llm(prompt)    \n",
    "\n",
    "\n",
    "def GPT_generation(prompt):\n",
    "  response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    n = 1,\n",
    "    stream = False,\n",
    "    temperature=0.0,\n",
    "    max_tokens=600,\n",
    "    top_p = 1.0,\n",
    "    frequency_penalty=0.0,\n",
    "    presence_penalty=0.0,\n",
    "    stop = [\"Q:\"]\n",
    "  )\n",
    "  return response['choices'][0]['message']['content']\n",
    "\n",
    "def GPT4_debug(prompt):\n",
    "  response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    n = 1,\n",
    "    stream = False,\n",
    "    temperature=0.0,\n",
    "    max_tokens=350,\n",
    "    top_p = 1.0,\n",
    "    frequency_penalty=0.0,\n",
    "    presence_penalty=0.0,\n",
    "    stop = [\"#\", \";\",\"\\n\\n\"]\n",
    "  )\n",
    "  return response['choices'][0]['message']['content']\n",
    "\n",
    "def saveDataJson(OUTPUT_PATH,list):\n",
    "    # Save the object to a JSON file\n",
    "    with open(OUTPUT_PATH, 'w') as json_file:\n",
    "        json.dump(list, json_file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_data_json(DATASET):\n",
    "    # Open the JSON file and load data\n",
    "    with open(DATASET, 'r') as json_file:\n",
    "        return json.load(json_file)\n",
    "\n",
    "def getdbPath(db_id):\n",
    "    # Modificar el PATH para donde este la base de datos\n",
    "    db_path = SPIDER_DB_DIR\n",
    "    db_uri = db_path + db_id + '/' + db_id + '.sqlite'\n",
    "    return db_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a14678-94f7-4424-8014-d21621d09e3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data samples 1034\n",
      "index is 300\n",
      "\n",
      "Gold: SELECT document_id ,  document_name ,  document_description FROM Documents\n",
      "\n",
      "Question:What are the ids, names, and descriptions for all documents?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    spider_schema,spider_primary,spider_foreign = creatiing_schema(DATASET_SCHEMA)\n",
    "    val_df = load_data(DATASET)\n",
    "    print(f\"Number of data samples {val_df.shape[0]}\")\n",
    "    CODEX = []\n",
    "    for index, row in val_df.iloc[300:].iterrows():\n",
    "        #if index < 405: continue #for testing\n",
    "        print(f\"index is {index}\")\n",
    "        print('\\nGold: '+row['query'])\n",
    "        print('\\nQuestion:'+row['question'])\n",
    "        \n",
    "        SQL = None\n",
    "        SQL_debug = None\n",
    "        predicted_class = None\n",
    "        schema_links = None\n",
    "        error_type = None\n",
    "        error_message = None\n",
    "        error_encountered = False\n",
    "        \n",
    "        if not error_encountered:\n",
    "            schema_links = []\n",
    "            try:\n",
    "                schema_links = local_generation(\n",
    "                    schema_linking_prompt_maker(row['question'], row['db_id']))\n",
    "            except Exception as e:\n",
    "                error_encountered = True\n",
    "                error_type = 'Cannot_generate_schema_link'\n",
    "                error_message = str(e)                \n",
    "            try:\n",
    "                schema_links = schema_links.split(\"Schema_links: \")[1]\n",
    "            except Exception as e:\n",
    "                error_encountered = True\n",
    "                error_type = 'Cannot_split_schema_link'\n",
    "                error_message = str(e) \n",
    "                schema_links = \"[]\"\n",
    "        print('\\nschema link: ' + schema_links)\n",
    "        if not error_encountered:\n",
    "            classification = None\n",
    "            try:\n",
    "                classification = local_generation(\n",
    "                    classification_prompt_maker(row['question'], row['db_id'], schema_links[1:]))\n",
    "            except Exception as e:\n",
    "                error_encountered = True\n",
    "                error_type = 'Cannot_generate_classification'\n",
    "                error_message = str(e) \n",
    "            try:\n",
    "                predicted_class = classification.split(\"Label: \")[1]\n",
    "            except:\n",
    "                print(\"Slicing error for the classification module\")\n",
    "                predicted_class = '\"NESTED\"'\n",
    "            print('\\nclassification: ' + predicted_class)\n",
    "        if not error_encountered:\n",
    "            if '\"EASY\"' in predicted_class and not error_encountered:\n",
    "                print(\"EASY\")\n",
    "                SQL = None\n",
    "                try:\n",
    "                    SQL = local_generation(easy_prompt_maker(row['question'], row['db_id'], schema_links))\n",
    "                except Exception as e:\n",
    "                    error_encountered = True\n",
    "                    error_type = 'cannot_generate_easy_query'\n",
    "                    error_message = str(e) \n",
    "            elif '\"NON-NESTED\"' in predicted_class:\n",
    "                print(\"\\nNON-NESTED\")\n",
    "                SQL = None\n",
    "                try:\n",
    "                    SQL = local_generation(medium_prompt_maker(row['question'], row['db_id'], schema_links))\n",
    "                except Exception as e:\n",
    "                    error_encountered = True\n",
    "                    error_type = 'cannot_generate_medium_query'\n",
    "                    error_message = str(e) \n",
    "                try:\n",
    "                    SQL = SQL.split(\"SQL: \")[1]\n",
    "                except Exception as e:\n",
    "                    error_encountered = True\n",
    "                    error_type = 'SQL_slicing_error'\n",
    "                    error_message = str(e) \n",
    "                    SQL = \"SELECT\"\n",
    "            else:\n",
    "                print(\"\\nNESTED\")\n",
    "                SQL = None\n",
    "                if not error_encountered:\n",
    "                    try:\n",
    "                        sub_questions = classification.split('questions = [\"')[1].split('\"]')[0]\n",
    "                        SQL = local_generation(\n",
    "                            hard_prompt_maker(row['question'], row['db_id'], schema_links, sub_questions))\n",
    "                    except Exception as e:\n",
    "                        error_encountered = True\n",
    "                        error_type = 'SQL_slicing_error_or_generation_error'\n",
    "                        error_message = str(e) \n",
    "                try:\n",
    "                    SQL = SQL.split(\"SQL: \")[1]\n",
    "                except Exception as e:\n",
    "                    error_encountered = True\n",
    "                    error_type = 'SQL_slicing_error'\n",
    "                    error_message = str(e) \n",
    "                    SQL = \"SELECT\"\n",
    "            print('\\nSQL:' + SQL)\n",
    "        debugged_SQL = None\n",
    "        if not error_encountered:\n",
    "            try:\n",
    "                debugged_SQL = local_debug(debuger(row['question'], row['db_id'], SQL)).replace(\"\\n\", \" \")\n",
    "            except Exception as e:\n",
    "                error_encountered = True\n",
    "                error_type = 'cannot_generate_debug'\n",
    "                error_message = str(e) \n",
    "            SQL_debug = \"SELECT \" + debugged_SQL\n",
    "            print('\\nSQL debug:'+SQL_debug)\n",
    "\n",
    "        CODEX.append({'question':row['question'],'gold_query':row['query'],'db_id': row['db_id'], \n",
    "                      'predicted_query': SQL, 'predicted_query_debug': SQL_debug, 'predicted_class':predicted_class,\n",
    "                      'predicted_schema_links':schema_links,\n",
    "                      'error_encountered':error_encountered, 'error_type': error_type, 'error_message':error_message})\n",
    "        if index == 600 :  break\n",
    "\n",
    "    OUTPUT_DIR = '/home/llmuser/models/results/DIN_SQL_Mixtral-300-500.json'\n",
    "    saveDataJson(OUTPUT_DIR, CODEX)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6b9cffe3-189f-40e7-891f-9a233adedcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryDB(database, SQL_query):\n",
    "    conn = sqlite3.connect(database)\n",
    "    # Create a cursor object to execute SQL queries\n",
    "    cursor = conn.cursor()\n",
    "    # Create a table\n",
    "    cursor.execute(\"PRAGMA case_sensitive_like = OFF\")\n",
    "    cursor.execute(SQL_query)\n",
    "    results = cursor.fetchall()\n",
    "    return results\n",
    "    # Close the cursor and connection\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "def evaluatePredict(CODEX):\n",
    "    count = 0\n",
    "    for row in CODEX:\n",
    "        predict_query_valid = True\n",
    "        db = getdbPath(row['db_id'])\n",
    "        error_encountered = False\n",
    "        error = None\n",
    "        error_type = None\n",
    "        predict_success = None\n",
    "        goldQueryValue = None\n",
    "        predQueryValue = None \n",
    "        try:\n",
    "            goldQueryValue =  queryDB(db, row['gold_query'])\n",
    "        except Exception as e:\n",
    "            error_encountered = True\n",
    "            error_type = 'Cannot_Query_Gold'\n",
    "            error_message = str(e)\n",
    "            predict_query_valid = False\n",
    "            goldQueryValue = None\n",
    "        pred_query = row['predicted_query']\n",
    "        try:\n",
    "            predQueryValue = queryDB(db, pred_query)\n",
    "        except Exception as e:\n",
    "            error_encountered = True\n",
    "            error_type = 'Cannot_Query_Pred'\n",
    "            error_message = str(e)\n",
    "            predQueryValue = None\n",
    "        if goldQueryValue == predQueryValue :\n",
    "            predict_success = True\n",
    "        else:\n",
    "            predict_success = False\n",
    "            error_encountered = True\n",
    "            error_type = 'Gold_Predict_Missmatch'\n",
    "            error_message = None\n",
    "        row.update({'predict_success':predict_success, 'gold_result':goldQueryValue, 'predict_result': predQueryValue,'predict_query_valid':predict_query_valid})\n",
    "        if error_encountered:\n",
    "            row['error_encountered'] = error_encountered\n",
    "            row['error_type'] = error_type\n",
    "            row['error_message'] = error_message\n",
    "    return CODEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0af1b295-1352-4d69-bd37-b3884a45480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET1 = load_data_json('/home/llmuser/models/results/DIN_SQL_Mixtral-1-25.json')\n",
    "DATASET2 = load_data_json('/home/llmuser/models/results/DIN_SQL_Mixtral-25-70.json')\n",
    "DATASET3 = load_data_json('/home/llmuser/models/results/DIN_SQL_Mixtral-70-300.json')\n",
    "DATASET4 = load_data_json('/home/llmuser/models/results/DIN_SQL_Mixtral-300-500.json')\n",
    "CODEX = DATASET1 + DATASET2 + DATASET3 + DATASET4\n",
    "\n",
    "CODEX_OUT = evaluatePredict(CODEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f2e335f2-3741-4085-bb3c-f0425fc00fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = '/home/llmuser/models/results/DIN_SQL_Mixtral-500-results.json'\n",
    "saveDataJson(OUTPUT_DIR, CODEX_OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c0f89aae-a2af-43ec-bff0-75d02cd094f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27037773359840955"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculateAccuracy(DATASET1):\n",
    "    df = pd.DataFrame(DATASET1)\n",
    "    success = df[df['predict_success']==True]\n",
    "    return len(success)/len(df)\n",
    "\n",
    "accuracy = calculateAccuracy(CODEX_OUT)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0a9a8111-a9c5-44f0-b6f2-f363606675af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_query</th>\n",
       "      <th>predicted_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SELECT avg(age) ,  min(age) ,  max(age) FROM s...</td>\n",
       "      <td>SELECT AVG(Age) AS AverageAge , MIN(Age) AS M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SELECT song_name ,  song_release_year FROM sin...</td>\n",
       "      <td>SELECT name ,  release_year FROM song WHERE r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SELECT song_name ,  song_release_year FROM sin...</td>\n",
       "      <td>SELECT name ,  release_year FROM song WHERE s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SELECT DISTINCT country FROM singer WHERE age ...</td>\n",
       "      <td>SELECT DISTINCT Country FROM singer WHERE Age...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SELECT country ,  count(*) FROM singer GROUP B...</td>\n",
       "      <td>SELECT country ,  COUNT(*) AS 'Number Of Sing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>SELECT avg(injured) FROM death</td>\n",
       "      <td>SELECT AVG(injured) FROM death WHERE killed  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>SELECT T1.killed ,  T1.injured FROM death AS T...</td>\n",
       "      <td>SELECT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>SELECT DISTINCT T1.id ,  T1.name FROM battle A...</td>\n",
       "      <td>SELECT id ,  name FROM battle WHERE id IN (SE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>SELECT T1.id ,  T1.name FROM battle AS T1 JOIN...</td>\n",
       "      <td>SELECT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>SELECT T2.id ,  T2.name FROM death AS T1 JOIN ...</td>\n",
       "      <td>SELECT id ,  name FROM ship WHERE id  IN (SEL...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>367 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            gold_query  \\\n",
       "5    SELECT avg(age) ,  min(age) ,  max(age) FROM s...   \n",
       "6    SELECT song_name ,  song_release_year FROM sin...   \n",
       "7    SELECT song_name ,  song_release_year FROM sin...   \n",
       "9    SELECT DISTINCT country FROM singer WHERE age ...   \n",
       "10   SELECT country ,  count(*) FROM singer GROUP B...   \n",
       "..                                                 ...   \n",
       "497                     SELECT avg(injured) FROM death   \n",
       "498  SELECT T1.killed ,  T1.injured FROM death AS T...   \n",
       "500  SELECT DISTINCT T1.id ,  T1.name FROM battle A...   \n",
       "501  SELECT T1.id ,  T1.name FROM battle AS T1 JOIN...   \n",
       "502  SELECT T2.id ,  T2.name FROM death AS T1 JOIN ...   \n",
       "\n",
       "                                       predicted_query  \n",
       "5     SELECT AVG(Age) AS AverageAge , MIN(Age) AS M...  \n",
       "6     SELECT name ,  release_year FROM song WHERE r...  \n",
       "7     SELECT name ,  release_year FROM song WHERE s...  \n",
       "9     SELECT DISTINCT Country FROM singer WHERE Age...  \n",
       "10    SELECT country ,  COUNT(*) AS 'Number Of Sing...  \n",
       "..                                                 ...  \n",
       "497   SELECT AVG(injured) FROM death WHERE killed  ...  \n",
       "498                                             SELECT  \n",
       "500   SELECT id ,  name FROM battle WHERE id IN (SE...  \n",
       "501                                             SELECT  \n",
       "502   SELECT id ,  name FROM ship WHERE id  IN (SEL...  \n",
       "\n",
       "[367 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(CODEX_OUT)\n",
    "df = df[df['predict_success']==False]\n",
    "df = df[['gold_query','predicted_query']]\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
